{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "continuous-parade",
   "metadata": {},
   "source": [
    "# Lab Risk management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-alliance",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e437821c-1b5a-4265-989f-347847984530",
   "metadata": {},
   "source": [
    "For the later we will import the usual libraries :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0fe154-d2df-4b58-9c64-3be42c193651",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import proj3d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-roots",
   "metadata": {},
   "source": [
    "In order to have 3D interractive visualization, it is necessary to activate the widget mode of matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb43024-19d8-48bb-8ed2-1071b48fbd8f",
   "metadata": {},
   "source": [
    "If ipympl is missing, you can install ipympl with the following command line (uncomment first). Be aware that a pip install can broke your python configuration. Use it if you are familiar with such command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b2bffe-8f2a-44f3-b0ba-2af22bf8fee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "traditional-child",
   "metadata": {},
   "source": [
    "## Lab 1 : PCA sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-surprise",
   "metadata": {},
   "source": [
    "The objectiv of this lab is to study the impact of correlated random variable throug the analysis of its principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-annex",
   "metadata": {},
   "source": [
    "### Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f953e82-9b36-4ad8-8724-a04968a06500",
   "metadata": {},
   "source": [
    "This first step intends to create a set of 3 correlated random variables. We define the number of point to draw, the average and volatility for each random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 400\n",
    "\n",
    "mu = np.array([5.0, 3.0, 10.0])\n",
    "sigma = np.array([5.0, 3.0, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314e0310-9e24-4fc8-84f6-30e16ead065c",
   "metadata": {},
   "source": [
    "As we intends to have corralated matrix, we will use the following correlation matrix :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f262ca4c-eead-42d9-96ac-da8c3d38957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = np.array([\n",
    "        [  1.00, -0.64, -0.97],\n",
    "        [ -0.64,  1.00,  0.57],\n",
    "        [ -0.97,  0.57,  1.00]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f774459-aed0-47cb-92af-7a6b32725413",
   "metadata": {},
   "source": [
    "You can visualise the object by directly input its name in a code cell:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de4091-c0bc-4ab2-972a-c8988b18162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e139cb3-af62-458e-8620-6460e2442e2e",
   "metadata": {},
   "source": [
    "You can also use print:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b11eb7-6c8d-4034-abda-059cb3c00ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a3b65c-c593-407f-b036-6ecdd382e2b0",
   "metadata": {},
   "source": [
    "We will use a generator of correlated variable that require a covariance matrix. Compute the covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c6a1b2-078c-423d-b7aa-2f8df81da931",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_matrix = correlation_matrix * np.outer(sigma,sigma)\n",
    "covariance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6854e8c9-c041-490c-ad0e-b04ea2c8327c",
   "metadata": {},
   "source": [
    "Once we have a covariance matrix, we can ask for correlated random variables that follow a normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07079e7-3424-49ba-9ace-998eb65d8f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the random samples.\n",
    "rng = np.random.default_rng()\n",
    "dataset = rng.multivariate_normal(mu, covariance_matrix, size=num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558ebb64-aff7-477a-8c85-ea7f5f712ca7",
   "metadata": {},
   "source": [
    "Lets inspect the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c80412-79e3-4dac-9db5-f4908d4bf2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8e1131-de08-4a7b-9c91-66c8308f38e1",
   "metadata": {},
   "source": [
    "In order to have the dimension of dataset, we can use shape function : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b327be-d6e1-4599-9701-b9398c7c98ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f177a4cf-dfc1-4c21-ac6c-aefc0123570b",
   "metadata": {},
   "source": [
    "Lets inspect the first element of the dataset variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf05e0-3002-463f-8e20-63f82afcadc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9b276b-2ae1-45e4-85b7-9a81729d676c",
   "metadata": {},
   "source": [
    "If we want the first random variable, we need to ask for all value on the first axis, and ask for the first element on the second variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d2377-5c03-4a94-b0fd-4529fc99db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde0a641-6ed7-4089-a7e2-ac05485b5b0d",
   "metadata": {},
   "source": [
    "If we only want to retreive the n first elements of the first random variable, we can use the slice operator (\":\") with a precision of boundaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2dfa0b-b8a1-43f7-9339-0f7f7ec4cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0:10,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8611de-b9fd-4ab9-8ce9-e7cf392f53e7",
   "metadata": {},
   "source": [
    "Lets store in x1, y1 and z1 the tree random variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54fad53-61d0-4ddd-add2-087712fc4960",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = dataset[:,0]\n",
    "y1 = dataset[:,1]\n",
    "z1 = dataset[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777a9922-7db0-4b2b-8ab6-1bd75a24cf4e",
   "metadata": {},
   "source": [
    "Lets plots those variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975017a9-1a3e-40ed-91dc-2f13fd6adda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot various projections of the samples.\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(x1, y1, 'b.', alpha=0.25)\n",
    "plt.plot(x1.mean(), y1.mean(), 'ro', ms=3.5)\n",
    "plt.ylabel('y')\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(x1, z1, 'b.', alpha=0.25)\n",
    "plt.plot(x1.mean(), z1.mean(), 'ro', ms=3.5)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('z')\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(y1, z1, 'b.', alpha=0.25)\n",
    "plt.plot(y1.mean(), z1.mean(), 'ro', ms=3.5)\n",
    "plt.xlabel('y')\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e94a14-2d8a-4ac2-a983-ef3915af4b0f",
   "metadata": {},
   "source": [
    "And in 3D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c207c75-440f-46cc-abcb-69295414e6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(x1, y1, z1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86913b4-b001-4a96-8eca-6bf68ae1f69e",
   "metadata": {},
   "source": [
    "Lets see if our dataset has the correct properties. Compute the average and standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc4c8f8-c3b2-4707-a540-4060c87b93e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_average = dataset.mean(axis=0)\n",
    "empirical_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c3b5bd-9577-4830-97d1-79ea999cfb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_average = dataset.std(axis=0)\n",
    "empirical_average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056afbf5-0741-4bf6-bd95-23b9c93d3dfc",
   "metadata": {},
   "source": [
    "Now we will normalize our dataset (average = 0 and standard deviation = 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efd57f8-ad4b-4ca3-8c37-14ded1ce8da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_dataset = (dataset - dataset.mean(axis=0))/dataset.std(axis=0)\n",
    "normalised_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcbea96-ca0c-45e9-be56-396fb3d4a446",
   "metadata": {},
   "source": [
    "Lets verify that our dataset still has the same look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a453ce90-2717-41cc-8330-8dd262c25d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2, y2, z2 = normalised_dataset[:,0], normalised_dataset[:,1], normalised_dataset[:,2]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(x2, y2, z2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d111a044-f42c-470e-acf0-e7480667f403",
   "metadata": {},
   "source": [
    "Now compute the correlation matrix of the normalized dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7a6948-3e98-4bad-898a-59b13588d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "noramlized_correlation_matrix = np.cov(normalised_dataset, rowvar=False)\n",
    "noramlized_correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb06132-0307-4ba5-94d8-a4374a619170",
   "metadata": {},
   "source": [
    "Then we compute the eigen values and eigen vectors of this normalized correlation matrix. Look in Numpy documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5635adff-2594-46a7-9a78-6dc296b605a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_values, eigen_vectors = np.linalg.eig(noramlized_correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5711acc2-bc5b-46c1-8877-e9edeb74aaab",
   "metadata": {},
   "source": [
    "Lets inspect eigen values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d300d5b6-4578-436b-a986-7311f760e71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799d3325-9bc1-4c23-82cb-bb58ec0cacd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "100*eigen_values/sum(eigen_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4fe5c6-5b0c-4e3e-b6ce-be84bbc27d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(eigen_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee2db0c-e6ea-48ba-85fa-ce8eab6de5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dee309d-0e72-4579-b3bb-1b3271470a94",
   "metadata": {},
   "source": [
    "For ease of usage, we will sort eigen values and vectors by order of magnitude of aigen values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc1634a-d072-4964-b890-068f14656f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_index=np.argsort(-eigen_values)\n",
    "sorted_eigen_values = eigen_values[sorted_index]\n",
    "sorted_eigen_vectors = eigen_vectors[:,sorted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a884b7d1-c231-4d2e-a541-6c12ee219f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_eigen_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87351efb-2769-4abf-9805-63d56ed693ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_eigen_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a369bc6-53be-406e-93cd-1fd3113e73aa",
   "metadata": {},
   "source": [
    "Now we choose the number of components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff08bd47-956d-405f-9522-202e98ee6fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_components = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce4873e-4f05-4330-b146-fb419fac4ab8",
   "metadata": {},
   "source": [
    "Select only the first nb_components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4aca26-802b-4c55-b5f9-19d0046d581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_eigen_vectors[:,:nb_components]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac615682-4029-465d-a588-0fca6d6ac013",
   "metadata": {},
   "source": [
    "To compute the principal components, multiply the normalised_dataset to the sorted_eigen_vectors. Use nb_components as a filter of number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635341ce-dc82-4379-816c-2c96c180f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_components = np.matmul(normalised_dataset,sorted_eigen_vectors[:,:nb_components])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8d80fc-15f2-4009-b5e4-4bc862b93499",
   "metadata": {},
   "source": [
    "Lets check some properties on the principal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93ff7c2-0a9a-49d0-889f-6e0b223cd692",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(principal_components.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230a7bd1-4cc9-49cb-aa42-2d36499c59e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(principal_components,rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e2eb65-3351-4c73-8cbd-f75b77075464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.cov(principal_components,rowvar=False).trace()\n",
    "print(np.sum(principal_components.std(axis=0)*principal_components.std(axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a296e80-0f31-4862-9bc8-fbf27fc3d468",
   "metadata": {},
   "source": [
    "No lets reconstruct the original dataset only using the selected components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc1caa7-46aa-4505-b441-b486d47c8ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_dataset= np.matmul(principal_components,np.transpose(sorted_eigen_vectors[:,:nb_components]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18eefaf-a806-46be-9371-819b0d958d91",
   "metadata": {},
   "source": [
    "As we have previously normilzed our dataset, lets denormlized the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28990429-6145-4b8d-8182-26721b54a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_dataset_denormalized = reconstructed_dataset * dataset.std(axis=0) + dataset.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef5bc5-b1ab-4a42-b77b-0c4f752f6c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_dataset_denormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33186a8f-df30-49af-9b07-60db6bc2582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7618c5b0-db90-4c01-a7ca-58187cd09a29",
   "metadata": {},
   "source": [
    "Lets see the differences between datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982bb774-1582-4f16-9b95-e3e66f46f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_dataset_denormalized - dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc030a41-a685-4ebf-a73b-340598211b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.average(abs(reconstructed_dataset_denormalized - dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d872a94f-89d7-4329-9477-d173c477a44e",
   "metadata": {},
   "source": [
    "And plot the reconstructed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cc1dd1-5383-41d2-8307-9812eb7438c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3, y3, z3 = reconstructed_dataset_denormalized[:,0], reconstructed_dataset_denormalized[:,1], reconstructed_dataset_denormalized[:,2]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(x3, y3, z3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11ea51d-7f16-4e80-b400-a58236460fea",
   "metadata": {},
   "source": [
    "Last try to modify number of components and observe the effect on the reconstructed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d9eec2-8fb7-4606-a1fa-8b241ae1f71b",
   "metadata": {},
   "source": [
    "##Â Lab 2: PCA on equity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f5958-5163-4b7d-bd7c-5bce0d21d0d9",
   "metadata": {},
   "source": [
    "We will work on 7 equity index that we will retreive on yahoo fincial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ea3e1-707d-4930-b0fb-7c0656a4ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_url = 'https://query1.finance.yahoo.com/v7/finance/download/{}?period1=1509235200&period2=1667001600&interval1&events=history'\n",
    "tickers = ['^GSPC','^FCHI','^FTSE','^NDX','^STOXX50E','^DJI','^IBEX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ddcd3e-d090-4f0c-a047-fc065c1f1b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.DataFrame()\n",
    "for ticker in tickers:\n",
    "    url = yahoo_url.format(ticker)\n",
    "    df_tmp = pd.read_csv(url)\n",
    "    df_tmp['Ticker'] = ticker\n",
    "    df_raw = pd.concat([df_raw, df_tmp[['Date','Ticker','Adj Close']]])\n",
    "df_raw.columns = ['date','ticker','price']\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d370fc5-2393-41fc-aaba-f382f51295fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_equity = df_raw.pivot_table(index=['date'], columns='ticker', values=['price'])\n",
    "df_equity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d343d7-adcd-43bb-97d0-d4083af6a074",
   "metadata": {},
   "source": [
    "Plot the equities time series directly using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40a7a78-ca82-447a-afbf-c19991214a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_equity.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb7e86d-8c1a-481b-af40-4390c4f8e4ff",
   "metadata": {},
   "source": [
    "Now, again using pandas, compute daly returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2e803-6174-4746-8f9b-b1b2e1515bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns = df_equity[\"price\"].pct_change()[1:]\n",
    "df_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e06df6-3d4a-4101-ad7a-c377e4bfdc69",
   "metadata": {},
   "source": [
    "And plot the returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0446506d-d6de-4352-a6fd-8cf005d357b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dfc842-b918-4541-a95b-3f40a98f0f43",
   "metadata": {},
   "source": [
    "Observe the histogram of returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff77155d-ca1f-4897-885a-17c354243815",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9899eac4-ed67-40f1-b81c-45c520231068",
   "metadata": {},
   "source": [
    "Now, compute the cumulated sum of historical returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c528f0bf-fa58-4ba2-b049-ee941fb79ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cumulated_returns = pd.DataFrame(df_returns.to_numpy().cumsum(axis=0))\n",
    "df_cumulated_returns.columns = df_returns.columns\n",
    "df_cumulated_returns.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee046fda-cd31-418c-9442-5f2113ff8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_returns.to_excel(\"df_equity.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f11e9fa-009d-4559-92f5-47a56e4ea720",
   "metadata": {},
   "source": [
    "Check the average return and associated volatility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aa8582-120c-4ee2-bde6-320c7d21f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a7f293-8711-4354-b066-e53d84ce43da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5963af7f-5ac4-4de7-9aba-43f920b8d21a",
   "metadata": {},
   "source": [
    "Now compute the normalized returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5de805-f1b0-4a9b-a361-80005786a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns_normalized =  (df_returns - df_returns.mean())/df_returns.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a77e792-21df-41a2-a80c-345c2729e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns_normalized.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc934ca-c7ae-4229-b77f-6f59769b5be3",
   "metadata": {},
   "source": [
    "And average return and volatility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13938213-046c-4616-98ed-067ef4656a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns_normalized.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54787e16-e8db-463f-a938-d0d2e3bbb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns_normalized.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb5844d-c219-4cee-90cb-b6ef0719a7ca",
   "metadata": {},
   "source": [
    "Compute the correlation matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b21c40-af1e-4b19-9806-7a8af8e6dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_correlation_matrix = df_returns_normalized.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28741c8e-0e4b-4a4e-9b70-deaa9de670c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2e0a3-1d0b-4a0f-8ec3-2409f6397668",
   "metadata": {},
   "source": [
    "Lets plot it with seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15201de2-6950-457a-899b-12f225e635ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.ioff():\n",
    "    fig = plt.figure()\n",
    "    sns.heatmap(equity_correlation_matrix,\n",
    "            xticklabels=equity_correlation_matrix.columns,\n",
    "            yticklabels=equity_correlation_matrix.columns)\n",
    "    display(fig)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2727e6-4e29-4fb1-a2c5-8299a0eb521d",
   "metadata": {},
   "source": [
    "Now we will extract time series from dataframe to numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa18fd-9381-458b-9f3d-63346943ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_correlation_matrix_np = equity_correlation_matrix.to_numpy()\n",
    "equity_correlation_matrix_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e65fa80-cf9e-4343-a7d8-2cb494e11c50",
   "metadata": {},
   "source": [
    "Computes the eigen values and vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03cad7b-8feb-4f0c-a987-03ec4aa5282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_eigen_values, equity_eigen_vectors = np.linalg.eig(equity_correlation_matrix_np)\n",
    "equity_sorted_index = np.argsort(-equity_eigen_values)\n",
    "equity_eigen_values_sorted = equity_eigen_values[equity_sorted_index]\n",
    "equity_eigen_vectors_sorted = equity_eigen_vectors[equity_sorted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcbbfbb-76c3-4c46-9ef7-4af7094c813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "100*equity_eigen_values_sorted/equity_eigen_values_sorted.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7edb92-8788-4b52-bcde-89756e882947",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = [100*equity_eigen_values_sorted[i]/equity_eigen_values_sorted.sum() for i in range(len(equity_eigen_values_sorted))]\n",
    "explained_variance\n",
    "fig = plt.figure()\n",
    "plt.bar(range(0,len(explained_variance)),explained_variance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab80afc-ad4a-45f3-a74f-057e6af2caaf",
   "metadata": {},
   "source": [
    "Compute the principal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e37b2-50bb-462c-9e09-7ef6cbd18283",
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_principal_components = np.matmul(df_returns_normalized.to_numpy(),equity_eigen_vectors_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9dcbbb-e86d-4d54-96f0-5720f345d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_nb_comp = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c546b008-d03b-4ea6-9736-92b915430984",
   "metadata": {},
   "source": [
    "Reconstruct the returns only using equity_nb_comp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afac8a5f-73bb-45c9-bad3-4a8987d72623",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_equity_returns = np.matmul(equity_principal_components[:,:equity_nb_comp], np.transpose(equity_eigen_vectors_sorted[:,:equity_nb_comp])) * df_returns.std().to_numpy() + df_returns.mean().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cabbd8c-83f2-4f11-a6e2-487510aef457",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_returns = pd.DataFrame(np.cumsum(new_equity_returns,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169cd32-464c-4add-8218-71a3a64ac1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_returns.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f569f9-c537-49e9-a322-aafd595d2a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cumulated_returns.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a367d216-ed87-4709-be87-a2e93bd7ff88",
   "metadata": {},
   "source": [
    "Mesure the error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a137e66-3540-4b44-bc0e-953d1690b0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6cf835-a8b9-4383-99f4-8aafecceebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(df_returns-new_equity_returns).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cdc257-97b5-4a09-9002-c55f1e8d7ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outTab = []\n",
    "\n",
    "for nb in range(1,len(df_returns.columns)+1):\n",
    "    temp_equity_returns = np.matmul(equity_principal_components[:,:nb], np.transpose(equity_eigen_vectors_sorted[:,:nb])) * df_returns.std().to_numpy() + df_returns.mean().to_numpy()\n",
    "    outTab.append([nb,abs(df_returns-temp_equity_returns).sum().sum()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54914a28-e6c9-4857-8747-f631e8e87a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outTab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c03f83-ec05-481f-86ea-95215e05ee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=7)\n",
    "out_pca = pca.fit_transform(df_returns_normalized)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.bar(range(0,len(pca.explained_variance_)),pca.explained_variance_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a3733c-c204-4aaf-9711-204429ca4090",
   "metadata": {},
   "source": [
    "# Lab 3: PCA on yield curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd13d56-d291-4be2-a127-10127dacbff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv(\"https://www.federalreserve.gov/data/yield-curve-tables/feds200628.csv\")\n",
    "\n",
    "try:\n",
    "    from urllib.request import Request, urlopen  # Python 3\n",
    "except ImportError:\n",
    "    from urllib2 import Request, urlopen  # Python 2\n",
    "\n",
    "req = Request(\"https://www.federalreserve.gov/data/yield-curve-tables/feds200628.csv\")\n",
    "req.add_header('User-Agent', 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:77.0) Gecko/20100101 Firefox/77.0')\n",
    "content = urlopen(req)\n",
    "\n",
    "df = pd.read_csv(content,skiprows=9)\n",
    "df = df.set_index(\"Date\")\n",
    "for column in df.columns:\n",
    "    if column[:5] != \"SVENY\":\n",
    "        df=df.drop(column,axis=1)\n",
    "df.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586d68a9-9e87-46b9-ac45-b4d96097fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f93ad34-a9ef-4cdf-b5eb-e99398ce428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a053b-836a-4f26-818b-0212f1718d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
